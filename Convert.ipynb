{"cells":[{"cell_type":"markdown","metadata":{"id":"9y81aC6nzAw1"},"source":["# Devanagari Phonetic Dictionary"]},{"cell_type":"markdown","metadata":{"id":"WbLzy9I-zAxE"},"source":["#### GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_QPQDT9zAxF","outputId":"1ea54660-8b8a-450e-bbe1-a4255b461f05","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["env: CUDA_VISIBLE_DEVICES=0\n"]}],"source":["#restricts the use of CUDA devices to only the first GPU in the system. This is useful when working with multi-GPU systems and wanting to limit the use of specific devices.\n","\n","%env CUDA_VISIBLE_DEVICES=0"]},{"cell_type":"markdown","metadata":{"id":"glYNruU2zAxI"},"source":["#### Download Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PUPysguLN1Lj","outputId":"dc564e74-c883-4e81-cdef-acb2646eaf5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in c:\\users\\vaibhav\\appdata\\roaming\\python\\python36\\site-packages (3.6.7)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vaibhav\\appdata\\roaming\\python\\python36\\site-packages (from nltk) (2022.10.31)\n","Requirement already satisfied: tqdm in c:\\users\\vaibhav\\appdata\\roaming\\python\\python36\\site-packages (from nltk) (4.64.1)\n","Requirement already satisfied: click in c:\\users\\vaibhav\\appdata\\roaming\\python\\python36\\site-packages (from nltk) (8.0.4)\n","Requirement already satisfied: joblib in c:\\users\\vaibhav\\appdata\\roaming\\python\\python36\\site-packages (from nltk) (1.1.1)\n","Requirement already satisfied: importlib-metadata in c:\\users\\vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages (from click->nltk) (4.8.3)\n","Requirement already satisfied: colorama in c:\\users\\vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages (from click->nltk) (0.4.4)\n","Requirement already satisfied: zipp>=0.5 in c:\\users\\vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages (from importlib-metadata->click->nltk) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages (from importlib-metadata->click->nltk) (4.1.1)\n","Requirement already satisfied: importlib-resources in c:\\users\\vaibhav\\appdata\\roaming\\python\\python36\\site-packages (from tqdm->nltk) (5.4.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["\n","pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gbTuQWvUN1Lk","outputId":"aaa8b1e3-4ef8-4c0a-d2d2-1877cf446d94"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in c:\\users\\vaibhav\\appdata\\roaming\\python\\python36\\site-packages (4.64.1)\n","Requirement already satisfied: colorama in c:\\users\\vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages (from tqdm) (0.4.4)\n","Requirement already satisfied: importlib-resources in c:\\users\\vaibhav\\appdata\\roaming\\python\\python36\\site-packages (from tqdm) (5.4.0)\n","Requirement already satisfied: zipp>=3.1.0 in c:\\users\\vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages (from importlib-resources->tqdm) (3.6.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["\n","pip install tqdm"]},{"cell_type":"markdown","metadata":{"id":"Uc22VWyTzAxK"},"source":["#### Import Stuff"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PSsNxFZgzAxL"},"outputs":[],"source":["import nltk\n","import tqdm\n","\n","#Python module that provides alternatives to Python's built-in container types, such as dictionaries, lists, and tuples.\n","#and is used to count the frequency of elements in a given list.\n","from collections import Counter\n","\n","#The tqdm_notebook function is a version of tqdm specifically designed to work with Jupyter notebooks.\n","from tqdm import tqdm_notebook\n","\n","# for working with multi-dimensional arrays and matrices.\n","import numpy as np\n","\n","#for building and training deep neural networks.\n","import tensorflow as tf\n","\n","#The seq2seq module contains a number of classes and functions for building sequence-to-sequence models, including encoder and decoder classes, attention mechanisms, and helper functions for training and inference.\n","from tensorflow.contrib import seq2seq\n","\n","#module contains a number of classes and functions for building recurrent neural network (RNN) models in TensorFlow.\n","#Dropout regularization is a technique used to prevent overfitting in neural networks. The basic idea is to randomly drop out (i.e., set to zero) some percentage of the outputs of a layer during training.\n","from tensorflow.contrib.rnn import DropoutWrapper\n","\n","#module is a built-in Python library that provides functions for generating random numbers and selecting random items from lists.\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie1SE8poN1Lm"},"outputs":[],"source":["tf.reset_default_graph()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4X81la_zAxL","outputId":"f99cf178-1624-4bfe-bc47-63081c459eeb"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\Vaibhav\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["#downloads the punkt dataset from the Natural Language Toolkit\n","#The punkt dataset contains pre-trained models and data for tokenizing natural language text into individual words and sentences.\n","nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{"id":"wtZWJ0o3zAxM"},"source":["#### Global Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Et1ohHIVzAxN"},"outputs":[],"source":["#\"MAX_SEQ_LEN\" and \"BATCH_SIZE\". These constants are used later to define the maximum length of input\n","#and output sequences and the number of sentences per batch.\n","\n","MAX_SEQ_LEN = 20\n","BATCH_SIZE = 64"]},{"cell_type":"markdown","metadata":{"id":"YKEKrqeNzAxN"},"source":["### Language Vocabulary \n","* (Vocab of characters, i.e. an Alphabet)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wIR-CKQxzAxP"},"outputs":[],"source":["#The Lang class provides methods for encoding and decoding sentences using a vocabulary of words learned from the text corpus. \n","#object counter containing the frequency counts of words in the text corpus, and an integer vocab_size indicating the maximum number of words to include in the vocabulary\n","#The constructor initializes the word-to-id and id-to-word mappings for the vocabulary, as well as special tokens for padding, start-of-sentence, end-of-sentence, and unknown words.\n","\n","\n","\n","\n","\n","class Lang:\n","    def __init__(self, counter, vocab_size):\n","        self.word2id = {}\n","        self.id2word = {}\n","        self.pad = \"<PAD>\"\n","        self.sos = \"<SOS>\"\n","        self.eos = \"<EOS>\"\n","        self.unk = \"<UNK>\"\n","        \n","        # is initialized to 0, which suggests that it may be used to represent a padding token. Padding tokens are often used to ensure that sequences of variable length can be processed efficiently in batches.\n","        self.ipad = 0\n","        #is initialized to 1, which suggests that it may be used to represent a start-of-sequence token. This token can be useful in tasks like sequence generation or machine translation, where the model needs to know when to start generating or translating a sequence.\n","        self.isos = 1\n","        # is initialized to 2, which suggests that it may be used to represent an end-of-sequence token. This token can be used in the same way as the start-of-sequence token, but to indicate the end of a generated or translated sequence.\n","        self.ieos = 2\n","        #is initialized to 3, which suggests that it may be used to represent an unknown token. This token is often used to handle out-of-vocabulary words or rare words that do not appear in the vocabulary of the model.\n","        self.iunk = 3\n","        \n","        \n","        self.word2id[self.pad] = 0\n","        self.word2id[self.sos] = 1\n","        self.word2id[self.eos] = 2\n","        self.word2id[self.unk] = 3\n","        \n","        self.id2word[0] = self.pad\n","        self.id2word[1] = self.sos\n","        self.id2word[2] = self.eos\n","        self.id2word[3] = self.unk\n","        \n","        curr_id = 4\n","        for w, c in counter.most_common(vocab_size):\n","            self.word2id[w] = curr_id\n","            self.id2word[curr_id] = w\n","            curr_id += 1\n","            \n","    #This method takes a string s as input and returns a list of word ids corresponding to the words in the sentence.\n","    #wseq = s.lower().strip()\n","\n","    #The \"encodeSentence\" method of the Lang class takes a sentence string as input and returns a list of word ids corresponding to the words in the sentence. \n","    # The method checks whether each word in the sentence is in the vocabulary and replaces it with the corresponding integer if it is, or with the \"<UNK>\" token if it is not.\n","    # If the \"max_len\" parameter is specified, the output list is padded with \"<PAD>\" tokens to have a fixed length of \"max_len\".\n","\n","    def encodeSentence(self, s, max_len=-1):\n","        wseq = s.strip()\n","        if max_len == -1:\n","            return [self.word2id[w] if w in self.word2id else self.iunk for w in wseq]\n","        else:\n","            return ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + [self.ieos] + [self.ipad]*max_len)[:max_len]\n","        \n","\n","    #wseq = wseq = s.lower().strip() \n","    #This method is similar to encodeSentence, but it also returns the actual length of the encoded sequence as a separate integer value.\n","    def encodeSentence2(self, s, max_len=-1):\n","        wseq = wseq = s.strip()\n","        return min(max_len, len(wseq)+1), \\\n","            ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + \\\n","                [self.ieos] + [self.ipad]*max_len)[:max_len]\n","    \n","\n","    #The \"decodeSentence\" method of the Lang class takes a list of word ids as input and returns the corresponding decoded sentence as a string. \n","    # The method looks up each word id in the \"id2word\" attribute and replaces the \"<UNK>\" token with \"UNK\".\n","    def decodeSentence(self, id_seq):\n","        id_seq = np.array(id_seq + [self.ieos])\n","        j = np.argmax(id_seq==self.ieos)\n","        s = ''.join([self.id2word[x] for x in id_seq[:j]])\n","        s = s.replace(self.unk, \"UNK\")\n","        return s"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IFQc057gzAxS"},"outputs":[],"source":["# Total number of samples to read\n","N = 7877"]},{"cell_type":"markdown","metadata":{"id":"2FgjMHxczAxT"},"source":["### Reading the data files\n","- Each line contains a hindi word in both English and Devnagari script"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["5947e9a466904f62a46e4992e7ce8689","fb139b8583df4ba29fcabf68910d335f","f2c918f27ede470fbf93feaf16f0c6d9","9b0841ece2e94083b95c228177ae23f0","cd1f3db9b54341e4bca51c1616693d11","6268f0f3e80d40a8803af8b04ca4c926"]},"id":"DLZ43OqBzAxU","outputId":"eb7d6c22-4869-4035-d130-64beea7a61b3"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages\\ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  # Remove the CWD from sys.path while we load stuff.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b0841ece2e94083b95c228177ae23f0","version_major":2,"version_minor":0},"text/plain":["Reading file::   0%|          | 0/7877 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages\\ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd1f3db9b54341e4bca51c1616693d11","version_major":2,"version_minor":0},"text/plain":["Processing inputs::   0%|          | 0/7877 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages\\ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6268f0f3e80d40a8803af8b04ca4c926","version_major":2,"version_minor":0},"text/plain":["Processing inputs::   0%|          | 0/7877 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Counter({'a': 11954, 'A': 7318, 'M': 2981, 'h': 2867, 'r': 2806, 't': 2630, 'k': 2584, 'E': 2515, 'y': 2508, 's': 2303, 'l': 2152, 'c': 2058, 'I': 1840, 'n': 1757, 'p': 1718, 'v': 1667, 'O': 1531, 'i': 1438, 'd': 1256, 'm': 1197, 'g': 1025, 'u': 914, 'b': 895, 'j': 760, 'D': 703, 'T': 690, 'N': 598, 'U': 490, 'L': 484, 'S': 111, 'o': 76, 'e': 26, 'H': 2, 'x': 2})\n","Counter({'ा': 6958, '्': 3439, 'ं': 2982, 'र': 2760, 'य': 2482, 'त': 2433, 'े': 2433, 'क': 2262, 'ल': 2152, 'च': 2052, 'ी': 1829, 'न': 1742, 'व': 1667, 'स': 1641, 'ो': 1510, 'प': 1498, 'ि': 1289, 'म': 1165, 'द': 976, 'ग': 784, 'ज': 705, 'ड': 692, 'श': 662, 'ु': 654, 'ट': 620, 'ण': 598, 'ब': 573, 'ह': 521, 'ू': 484, 'ळ': 484, 'आ': 368, 'भ': 322, 'ख': 322, 'ध': 280, 'अ': 258, 'घ': 241, 'उ': 238, 'थ': 197, 'फ': 194, 'ष': 111, 'ए': 82, 'ठ': 70, 'ॉ': 65, 'इ': 63, 'ॅ': 56, 'ै': 44, 'ृ': 43, 'झ': 40, 'ऱ': 40, 'ँ': 32, 'ओ': 23, 'ौ': 21, 'ञ': 15, 'ऑ': 12, 'ढ': 11, 'ई': 11, 'छ': 7, 'ऊ': 6, '़': 4, 'य़': 4, 'ः': 2, 'ऋ': 2, '।': 1, 'औ': 1})\n"]}],"source":["#The Hindi and English sentences are stored separately in the hi_sentences and en_sentences lists.\n","# A Counter object is created for each language, and the frequency counts of each character in the sentences \n","#are added to the appropriate Counter object using a loop.\n","\n","hi_counter = Counter()\n","hi_sentences=[]\n","en_counter = Counter()\n","en_sentences=[]\n","with open(\"sorted_mapped_output_female_16_20.txt\", encoding=\"utf8\") as f:\n","    for line in tqdm_notebook(f, total=N, desc=\"Reading file:\"):\n","        en, hi = line.strip().split(\"\\t\")\n","        hi_sentences.append(hi)\n","        en_sentences.append(en)\n","    for line in tqdm_notebook(hi_sentences, desc=\"Processing inputs:\"):\n","        for w in line.strip():\n","            hi_counter[w] += 1\n","            \n","    for line in tqdm_notebook(en_sentences, desc=\"Processing inputs:\"):\n","        for w in line.strip():\n","            en_counter[w] += 1\n","\n","print(hi_counter)\n","print(en_counter)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZwQkFXW9zAxV","outputId":"72154c7f-2746-4a7a-f04c-a7d6ac882cd5","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Most common hi characters in dataset:\n"," [('a', 11954), ('A', 7318), ('M', 2981), ('h', 2867), ('r', 2806), ('t', 2630), ('k', 2584), ('E', 2515), ('y', 2508), ('s', 2303)]\n","\n","Total (hi)characters gathered from dataset: 34\n","\n","Most common en characters in dataset:\n"," [('ा', 6958), ('्', 3439), ('ं', 2982), ('र', 2760), ('य', 2482), ('त', 2433), ('े', 2433), ('क', 2262), ('ल', 2152), ('च', 2052)]\n","\n","Total (en)characters gathered from dataset: 64\n"]}],"source":["# A few sample hindi characters\n","print(\"Most common hi characters in dataset:\\n\", hi_counter.most_common(10))\n","\n","print(\"\\nTotal (hi)characters gathered from dataset:\",len(hi_counter))\n","\n","# A few sample english characters\n","print(\"\\nMost common en characters in dataset:\\n\", en_counter.most_common(10))\n","\n","print(\"\\nTotal (en)characters gathered from dataset:\", len(en_counter))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_lxX669bzAxW"},"outputs":[],"source":["# Passed through the class to initiate the attributes\n","en_lang = Lang(en_counter, len(en_counter))\n","hi_lang = Lang(hi_counter, len(hi_counter))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqGQaGKlzAxW","outputId":"c5487094-7f51-4dd8-b07e-dffeb5f05e30","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test en encoding: [26, 27, 11, 5, 7, 20, 8, 4]\n","Test en decoding: शुक्रिया\n","Test hindi encoding: [33, 7, 25, 10, 8, 21, 12, 4, 2, 0]\n","Test hindi decoding: Shukriya\n"]}],"source":["print(\"Test en encoding:\", en_lang.encodeSentence(\"शुक्रिया\"))\n","\n","print(\"Test en decoding:\", en_lang.decodeSentence(en_lang.encodeSentence(\"शुक्रिया\", 10)))\n","\n","print(\"Test hindi encoding:\", hi_lang.encodeSentence(\"Shukriya\", 10))\n","\n","print(\"Test hindi decoding:\", hi_lang.decodeSentence((hi_lang.encodeSentence(\"Shukriya\", 10))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V1P1oauDzAxY"},"outputs":[],"source":["#The variables VE and VH represent the vocabulary sizes of the English and Hindi language models\n","\n","VE = len(en_lang.word2id)\n","VH = len(hi_lang.word2id)"]},{"cell_type":"markdown","metadata":{"id":"6b_SrHkhzAxY"},"source":["### The Seq2Seq architecture\n"]},{"cell_type":"markdown","metadata":{"id":"AmRN1DPEzAxZ"},"source":["#### Character Embedding Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZRdCRwSzAxZ"},"outputs":[],"source":["#These variables represent the word embedding matrices for English and Hindi languages. \n","# Word embeddings are dense vector representations of words in a high-dimensional space \n","#that capture the semantic and syntactic meaning of words. In this case, the embedding \n","#dimension is 300.\n","#The get_variable() method creates a variable with the given name and shape, and the dtype \n","# argument specifies the data type of the values stored in the variable, which is tf.float32 in this case.\n","# By default, these variables are trainable, which means that their values can be updated during the training process.\n","\n","en_word_emb_matrix = tf.get_variable(\"en_word_emb_matrix\", (VE, 300), dtype=tf.float32)\n","hi_word_emb_matrix = tf.get_variable(\"hi_word_emb_matrix\", (VH, 300), dtype=tf.float32)"]},{"cell_type":"markdown","metadata":{"id":"GVbkPMFEzAxa"},"source":["#### Placeholders\n","- Input to a tensorflow graph is "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FtMGZzhjzAxu"},"outputs":[],"source":["#keep_prob: A scalar placeholder with tf.float32 datatype, which represents the dropout keep probability. Dropout is a regularization technique used to prevent overfitting in neural networks. The keep_prob placeholder is used to pass the dropout keep probability as a feed_dict during training.\n","\n","#input_ids: A 2D placeholder tensor with tf.int32 datatype and shape (None, MAX_SEQ_LEN). This placeholder is used to pass the input sequences to the model during training and inference. MAX_SEQ_LEN is the maximum sequence length of the input sequences and None indicates that the batch size can be variable.\n","\n","#input_lens: A 1D placeholder tensor with tf.int32 datatype and shape (None,). This placeholder is used to pass the length of each input sequence to the model during training and inference. None indicates that the batch size can be variable.\n","\n","#ph_target_ids: A 2D placeholder tensor with tf.int32 datatype and shape (None, MAX_SEQ_LEN). This placeholder is used to pass the target sequences to the model during training. MAX_SEQ_LEN is the maximum sequence length of the target sequences and None indicates that the batch size can be variable.\n","\n","#target_lens: A 1D placeholder tensor with tf.int32 datatype and shape (None,). This placeholder is used to pass the length of each target sequence to the model during training. None indicates that the batch size can be variable.\n","\n","\n","keep_prob = tf.placeholder(tf.float32)\n","\n","input_ids = tf.placeholder(tf.int32, (None, MAX_SEQ_LEN))\n","input_lens = tf.placeholder(tf.int32, (None, ))\n","\n","ph_target_ids = tf.placeholder(tf.int32, (None, MAX_SEQ_LEN))\n","target_lens = tf.placeholder(tf.int32, (None, ))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggutj7fxzAxv"},"outputs":[],"source":["# Add SOS or GO symbol\n","#The tf.fill() function creates a tensor of shape [BATCH_SIZE, 1] and fills it with hi_lang.isos value. \n","#This tensor represents the start-of-sequence token for each batch element in the target sequences.\n","\n","target_ids = tf.concat([tf.fill([BATCH_SIZE,1], hi_lang.isos), ph_target_ids], -1)"]},{"cell_type":"markdown","metadata":{"id":"ahi01FiuzAxx"},"source":["#### Building the computation graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r4Z7ZRqzzAxy"},"outputs":[],"source":["input_emb = tf.nn.embedding_lookup(en_word_emb_matrix, input_ids)\n","target_emb = tf.nn.embedding_lookup(hi_word_emb_matrix, target_ids[:, :-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OKYHyXCzAxy","outputId":"a429b1f1-6dd5-4fb3-e16d-34139b6a2116"},"outputs":[{"data":{"text/plain":["TensorShape([Dimension(None), Dimension(20), Dimension(300)])"]},"execution_count":138,"metadata":{},"output_type":"execute_result"}],"source":["#  the shape of input_emb tensor would be (batch_size, max_seq_len, embedding_dim)\n","input_emb.shape"]},{"cell_type":"markdown","metadata":{"id":"J9pBD387zAxz"},"source":["#### Encoder - RNN based sequence encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fyzNjRuPzAxz"},"outputs":[],"source":["encoder_cell = tf.nn.rnn_cell.GRUCell(128) # The 128 argument specifies the number of hidden units in the GRU cell.\n","encoder_cell = DropoutWrapper(encoder_cell, output_keep_prob=keep_prob) #  Dropout is a regularization technique that randomly drops out (sets to zero) some of the neuron activations during training to prevent overfitting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LHgITaBQzAxz","outputId":"584017f8-2404-4ee4-84f1-e9c63ddd90e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F50438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F50438>>: AttributeError: module 'gast' has no attribute 'Str'\n","WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F50438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F50438>>: AttributeError: module 'gast' has no attribute 'Str'\n"]}],"source":["# enc_outputs: It is a tensor of shape (batch_size, max_seq_len, hidden_units), \n","#where hidden_units is the number of hidden units in the GRU cell (128 in this case). \n","#It contains the hidden state of the encoder at each time step for each input sequence in the batch. \n","# enc_state: It is a tensor of shape (batch_size, hidden_units), which contains the final hidden state of the encoder for each input sequence in the batch. This final hidden state is typically used as the initial state of the decoder.\n","\n","enc_outputs, enc_state = tf.nn.dynamic_rnn(\n","    encoder_cell, # The encoder GRU cell\n","    input_emb, # Embedded input sequence\n","    sequence_length=input_lens, # Sequence lengths of individual inputs in a batch\n","    initial_state=encoder_cell.zero_state(BATCH_SIZE, dtype=tf.float32)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLe5KTHuzAx0","outputId":"bc63f778-0cda-48e4-edc3-1beeecc13694"},"outputs":[{"data":{"text/plain":["TensorShape([Dimension(64), Dimension(128)])"]},"execution_count":141,"metadata":{},"output_type":"execute_result"}],"source":["# Confirm the shape of the final hidden state\n","enc_state.shape"]},{"cell_type":"markdown","metadata":{"id":"31XUMAiYzAx0"},"source":["#### Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sFEOCbY-zAx0"},"outputs":[],"source":["#  The output_keep_prob parameter specifies the probability that each output element will be kept during training. In other words, it controls the dropout rate for the output of the cell.\n","\n","decoder_cell = tf.nn.rnn_cell.GRUCell(128)\n","decoder_cell = DropoutWrapper(decoder_cell, output_keep_prob=keep_prob)"]},{"cell_type":"markdown","metadata":{"id":"-mrlSFWpzAx1"},"source":["#### Decoder to Output Vocab Projection Layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AzVN3kUFzAx1"},"outputs":[],"source":["# a fully connected layer is being created using the Dense class from the TensorFlow layers module.\n","output_projection = tf.layers.Dense(len(hi_lang.word2id))"]},{"cell_type":"markdown","metadata":{"id":"6x9LZRuYzAx1"},"source":["#### Decoder Training Helper"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmYOaiqrzAx1","outputId":"43952237-2b00-4a36-d407-a315eb13bc33"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F86908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F86908>>: AttributeError: module 'gast' has no attribute 'Str'\n","WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F86908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F86908>>: AttributeError: module 'gast' has no attribute 'Str'\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000156E0690B38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000156E0690B38>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000156E0690B38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000156E0690B38>>: AttributeError: module 'gast' has no attribute 'Index'\n"]}],"source":["helper = seq2seq.TrainingHelper(target_emb, target_lens)\n","decoder = seq2seq.BasicDecoder(decoder_cell, helper, enc_state, output_projection)\n","\n","#The outputs variable stores the output sequence generated by the decoder, and outputs_lens is a tensor representing the length of each output sequence.\n","outputs, _, outputs_lens = seq2seq.dynamic_decode(decoder, maximum_iterations=MAX_SEQ_LEN, \n","                                                  impute_finished=False, swap_memory=True) # The impute_finished parameter is a boolean that determines whether to use the final state of the decoder when the sequence has ended. The swap_memory parameter is a boolean that determines whether to swap the memory between CPU and GPU during the decoding process.\n","\n","#The reduce_max function is used to find the maximum length of the output sequence across all the sequences in the batch.\n","output_max_len = tf.reduce_max(outputs_lens)"]},{"cell_type":"markdown","metadata":{"id":"-W9q1dC1zAx1"},"source":["#### And Decoder Inference Helper"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvYv9TnJzAx2","outputId":"fcd331b7-76e7-4ccd-993e-160de62556fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F86908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F86908>>: AttributeError: module 'gast' has no attribute 'Str'\n","WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F86908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x00000156D9F86908>>: AttributeError: module 'gast' has no attribute 'Str'\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000156E0690B38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000156E0690B38>>: AttributeError: module 'gast' has no attribute 'Index'\n","WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000156E0690B38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000156E0690B38>>: AttributeError: module 'gast' has no attribute 'Index'\n"]}],"source":["# Using the decoder_cell without dropout here.\n","infer_helper = seq2seq.GreedyEmbeddingHelper(hi_word_emb_matrix, tf.fill([BATCH_SIZE, ], hi_lang.isos), hi_lang.ieos)\n","infer_decoder = seq2seq.BasicDecoder(decoder_cell, infer_helper, enc_state, output_projection)\n","infer_output = seq2seq.dynamic_decode(infer_decoder, maximum_iterations=MAX_SEQ_LEN, swap_memory=True)"]},{"cell_type":"markdown","metadata":{"id":"m_6ZJjSAzAx2"},"source":["#### Loss and Optimizers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p4U0MNlmzAx4"},"outputs":[],"source":["# Sequence mask:\n","# To make sure we don't back-propagate error from output of length positions\n","masks = tf.sequence_mask(target_lens, output_max_len, dtype=tf.float32, name='masks')\n","\n","# Loss function - weighted softmax cross entropy\n","cost = seq2seq.sequence_loss(\n","    outputs[0],\n","    target_ids[:, 1:(output_max_len + 1)],\n","    masks)\n","\n","# Optimizer\n","optimizer = tf.train.AdamOptimizer(0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IxI9SO99zAx_"},"outputs":[],"source":["train_op = optimizer.minimize(cost)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RCJR6kahzAyA"},"outputs":[],"source":["# the global variables are added to a computation graph, but their values are not initialized until the graph is executed.\n","init = tf.global_variables_initializer()"]},{"cell_type":"markdown","metadata":{"id":"_zKCuW56zAyA"},"source":["#### Tensorflow Sessions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sBIWAWsszAyA"},"outputs":[],"source":["sess_config = tf.ConfigProto()\n","sess_config.gpu_options.allow_growth = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8RyJB3_PzAyA","outputId":"775f59e0-3fbe-49c2-8dde-8eba77bb533e"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]}],"source":["sess = tf.InteractiveSession(config=sess_config)\n","sess.run(init)"]},{"cell_type":"markdown","metadata":{"id":"Fy6f6eJOzAyB"},"source":["#### Minibatch Training + Validation\n","- Performance Evaluation using BLEU scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4eGLJ62QzAyB"},"outputs":[],"source":["random.seed(41)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nduaa5nEzAyB"},"outputs":[],"source":["parallel = list(zip(en_sentences, hi_sentences))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QaNx8i85zAyF"},"outputs":[],"source":["random.shuffle(parallel)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9vrADg9WzAyF","outputId":"cf1ef9a4-5209-44e6-c3f7-ac18b7444593"},"outputs":[{"data":{"text/plain":["('काडटना', 'kADaTanA')"]},"execution_count":154,"metadata":{},"output_type":"execute_result"}],"source":["parallel[1000]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ITB3VvZQzAyF"},"outputs":[],"source":["train_n = int(0.95*N)\n","valid_n = N - train_n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjyLnQLUzAyG"},"outputs":[],"source":["train_pairs = parallel[:train_n].copy()\n","valid_pairs = parallel[train_n:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNpZk3DvzAyG"},"outputs":[],"source":["def small_test():\n","    all_bleu = []\n","    smoothing = nltk.translate.bleu_score.SmoothingFunction().method7\n","    for m in range(0, valid_n, BATCH_SIZE):\n","        # print(f\"Status: {m}/{N}\", end='\\r')\n","        n = m + BATCH_SIZE\n","        if n > valid_n:\n","            # print(\"Epoch Complete...\")\n","            break\n","\n","        input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n","        input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n","        for i in range(m, n):\n","            b,a = en_lang.encodeSentence2(valid_pairs[i][0], MAX_SEQ_LEN)\n","            input_batch[i-m,:] = a\n","            input_lens_batch[i-m] = b\n","\n","    #     target_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n","    #     target_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n","    #     for i in range(m, n):\n","    #         b,a = hi_lang.encodeSentence2(valid_pairs[i][1], MAX_SEQ_LEN)\n","    #         target_batch[i-m,:] = a\n","    #         target_lens_batch[i-m] = b\n","\n","        feed_dict={\n","            input_ids: input_batch,\n","            input_lens: input_lens_batch,\n","            #target_ids: target_batch,\n","            #target_lens: target_lens_batch,\n","            keep_prob: 1.0\n","        }\n","        pred_batch = sess.run(infer_output[0].sample_id, feed_dict=feed_dict)\n","        for k, pred_ in enumerate(pred_batch):\n","            pred_s = hi_lang.decodeSentence(list(pred_))\n","        \n","            ref = valid_pairs[m+k][1]\n","            try:\n","                _bx = nltk.translate.bleu_score.sentence_bleu(\n","                    [ref],\n","                    pred_s,\n","                    weights=[1/4]*4,\n","                    smoothing_function=smoothing)\n","            except ZeroDivisionError:\n","                _bx = 0\n","            all_bleu.append(_bx)\n","\n","    print(f\"BLEU Score: {np.mean(all_bleu)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["da17e6a932a545b39e61b937905bf46f","292b4d11c0294e25a79758ac51577305","77f62714885e465285e8d9082c41b05c","db2df59f776e49b79ff97ebfe27ae188","b33824c8562241f691eb9047da309b66","dbcec9efe94b4aa4871ce7bc099a7be4","27e4566b5e7a4d34b51829bbd6285289","8dc40ff9c0e6440a937abf700617e0fc","901f3114dfcc4162b0cbc86bc39dde0b","a6c0cf55523b475685f6a5e0029ea7b7","5aa718f4a5024e38b938b723ad576ca0","3a072ace26554de996d3b46d3e666811","5388bb3d67e84542b78d296decef9526","8914860d954643e48b87c2d8fc18010b","1c5d364a3c9641c8a11cf6bf403ace78","48a2553134224d24978b2fd7380b6705","949eb8c9d917433692fdddaeaca0a325","06c2d091916e48ce9de9e13c9b151689","eb483f5f8b714457abe77cd01599d492","ec1463527c5b40d7a6095751db459658","b03ad5bf10b347b6a50607d901ea0312","f9a9732fc11a4e508a9058767c26e051","3b5d879150884123a53a497a47db69ca","09a465ed5d0f4306a43b2107623f821c","be266ddba53e46c18bcb4c9cb41be3d3","d9459908f863451594d4f7b233a78d9e","404a8f67c41f4b9d9ba07c131cd638ea","56ec9215935e45dab3c8d8ebde830c8f","a54a05eb0f3e47c7bf6570a2d42cc3b1","7c012792b23743e7af3855210ade1bec","83e062872e314981af079b6f632012c1","b05b5919f3d14967b0f3289c39df6349","f90d78a577cd43a1adec407b58dd1105","bfe97828bfee44e1837242a8ff832f31","85dfdca22394403090d5ff04fbbee847","569bc5e8bb32451fbbf0c50c05e51e17","ec56aa3982c644869d45761cece04139","c9dafa2274974c24b7e934dcf3b42cf8","a111676e0dc34892bf1c3bfcc6ad91cd","b1eb732a213642058fc3c75aa39958a7","fedc1a0daa5a4929a5a9b166c58d90f7","a6dc05cd850741baa1e944bd4cbb87f8","9cddd0e9f85d4598935eabd6439ff6f5","0cfded77c08a4d36aff7caa82b4a8b25","9d87c54e57a6473b806a55d59d8f96d3","d79a5c31b8f34739a30a61f04e9754d4","6c6f27186b15422c9718a5bf5134fac7","b269e8269d2f4cd394e0b22389c05300","012198daedf842439869b41a5260de2c","a24a8896cf894fcba26ef0ccb78bd5ca","10de802a94044b2683d500fc89e4c993","973f12d9efed44b79c99952bf6932c93","1169c0d03fe248a78005778354713682","65d0a700dc784d7da2ace4b203e49d78","3130261663d047f787d6065d4650095c","a63faa1cfee84d7f924db539e4d28c57","ca5787922b2f4da4a4272c60fbbc4dc3","ac5ff54b979f4570b0833a826e2db0d1","3db225b699d144c1b5a82a7dd8e449bc","9398a24f4e784f6cb2f26192c1b7de68"]},"id":"h41XJM_FzAyG","outputId":"ff445398-a7b8-4269-ed6a-24349e88745c","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages\\ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b03ad5bf10b347b6a50607d901ea0312","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.01955027078264301\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9a9732fc11a4e508a9058767c26e051","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.060994858643850514\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b5d879150884123a53a497a47db69ca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.11542191180109107\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09a465ed5d0f4306a43b2107623f821c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.1525390244916027\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be266ddba53e46c18bcb4c9cb41be3d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.1714182470242307\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9459908f863451594d4f7b233a78d9e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.18232115814426575\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"404a8f67c41f4b9d9ba07c131cd638ea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.18626336626731255\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56ec9215935e45dab3c8d8ebde830c8f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.1948035644019183\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a54a05eb0f3e47c7bf6570a2d42cc3b1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.2008163796729574\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c012792b23743e7af3855210ade1bec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.20869660749675253\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83e062872e314981af079b6f632012c1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.2162474553607648\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b05b5919f3d14967b0f3289c39df6349","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.2192445568312429\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f90d78a577cd43a1adec407b58dd1105","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.22418407606930227\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bfe97828bfee44e1837242a8ff832f31","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.23753884846963388\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"85dfdca22394403090d5ff04fbbee847","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.23805692814003362\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"569bc5e8bb32451fbbf0c50c05e51e17","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.24232570962875846\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec56aa3982c644869d45761cece04139","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.2511248081943391\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9dafa2274974c24b7e934dcf3b42cf8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.24915593988385634\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a111676e0dc34892bf1c3bfcc6ad91cd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.25787318497331047\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1eb732a213642058fc3c75aa39958a7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.2614290358968383\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fedc1a0daa5a4929a5a9b166c58d90f7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.27176945666940516\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6dc05cd850741baa1e944bd4cbb87f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.2662785985991072\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9cddd0e9f85d4598935eabd6439ff6f5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.27364929501081403\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0cfded77c08a4d36aff7caa82b4a8b25","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.27837869744617283\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d87c54e57a6473b806a55d59d8f96d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.27998495465953216\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d79a5c31b8f34739a30a61f04e9754d4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.2830538142660309\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c6f27186b15422c9718a5bf5134fac7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.30318950254467586\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b269e8269d2f4cd394e0b22389c05300","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.308692604803602\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"012198daedf842439869b41a5260de2c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.31865452234291036\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a24a8896cf894fcba26ef0ccb78bd5ca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.31286476038560235\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10de802a94044b2683d500fc89e4c993","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.32123687642250626\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"973f12d9efed44b79c99952bf6932c93","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.3331398113519698\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1169c0d03fe248a78005778354713682","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.32734761071338087\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65d0a700dc784d7da2ace4b203e49d78","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.33638346704655686\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3130261663d047f787d6065d4650095c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.3478019570414446\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a63faa1cfee84d7f924db539e4d28c57","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.3564424163381694\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca5787922b2f4da4a4272c60fbbc4dc3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.36876354051191096\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac5ff54b979f4570b0833a826e2db0d1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.36813060255035374\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3db225b699d144c1b5a82a7dd8e449bc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BLEU Score: 0.3788488470715002\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9398a24f4e784f6cb2f26192c1b7de68","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["saver = tf.train.Saver()\n","\n","for _e in range(70):\n","    # Mix things up a bit.\n","    random.shuffle(train_pairs)\n","    pbar = tqdm_notebook(range(0, train_n, BATCH_SIZE))\n","    batch_loss = 0\n","    bxi = 0\n","    for m in pbar:\n","        n = m + BATCH_SIZE\n","        if n <= train_n:\n","            # print(\"Epoch Complete... \\n\")\n","\n","            input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n","            input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n","            for i in range(m, n):\n","                b,a = en_lang.encodeSentence2(train_pairs[i][0], MAX_SEQ_LEN)\n","                input_batch[i-m,:] = a\n","                input_lens_batch[i-m] = b\n","\n","            target_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n","            target_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n","            for i in range(m, n):\n","                b,a = hi_lang.encodeSentence2(train_pairs[i][1], MAX_SEQ_LEN)\n","                target_batch[i-m,:] = a\n","                target_lens_batch[i-m] = b\n","\n","            feed_dict={\n","                input_ids: input_batch,\n","                input_lens: input_lens_batch,\n","                ph_target_ids: target_batch,\n","                target_lens: target_lens_batch,\n","                keep_prob: 0.8 \n","            }\n","            sess.run(train_op, feed_dict=feed_dict)\n","            batch_loss += sess.run(cost, feed_dict=feed_dict)\n","            pbar.set_description(f\"Epoch: {_e} >> Loss: {batch_loss/(bxi+1):2.2F}:\")\n","            bxi += 1\n","            if (1 + n//BATCH_SIZE) % 100 == 0:\n","                small_test()\n","\n","    saver.save(sess, 'C:/Users/Vaibhav/Desktop/data/ModelOutputs')\n","    saver.save(sess, f'C:/Users/Vaibhav/Desktop/data/ModelOutputs/model_{_e}')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZWPuuAdN1L5","outputId":"bc657aa1-bedc-4a1e-e61e-c712c5a97c12"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\Vaibhav\\anaconda3\\envs\\python3_6\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from C:/Users/Vaibhav/Desktop/data/ModelOutputs/model_69\n"]}],"source":["saver = tf.train.Saver()\n","saver.restore(sess, \"C:/Users/Vaibhav/Desktop/data/ModelOutputs/model_69\")\n"]},{"cell_type":"markdown","metadata":{"id":"lIj1AXeEzAyH"},"source":["### Let's see some real translation examples now!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MeGK0ZGezAyI"},"outputs":[],"source":["def transliterate(s):\n","    input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n","    input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n","    b,a = en_lang.encodeSentence2(s, MAX_SEQ_LEN)\n","    input_batch[0, :] = a\n","    input_lens_batch[0] = b\n","    \n","    feed_dict={\n","        input_ids: input_batch,\n","        input_lens: input_lens_batch,\n","        #target_ids: target_batch,\n","        #target_lens: target_lens_batch,\n","        keep_prob: 1.0\n","    }\n","    pred_batch = sess.run(infer_output[0].sample_id, feed_dict=feed_dict)\n","    pred_ = pred_batch[0]\n","    pred_s = hi_lang.decodeSentence(list(pred_))\n","    # ref = valid_pairs[m+k][1]\n","    return pred_s"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVsbhpoLN1L6","outputId":"fa32732c-ad13-4fa2-d11c-6e5fb3d4f560"},"outputs":[{"name":"stdout","output_type":"stream","text":["bhAratIya janatA pakSAcI tIna disAMcI ciMtana basakA shisavAcO thaMDajasAMtI kAla sOMpalIya basakEMtalE carcE parasa AdalyA saMrakSaNa maMtryAka dhAMvaDAvapArEM karaNEcacE caDa paDasAda uThalEM basakEcE dOna dIsa payalIM rASTrIya svayadAMtalETa saMghAcE sarasaMgalhEka mOhana bhAgavatAna pakSAna taraNATyA ragatAka vAva divapAka jAya mhUNa sAMgata lAlakrmal aDavANI AnI tAMcE prilyAM phuDAyakAM kAvalAMta vacapAcI shiTakAvaNI dillIM saMghAcyA rAjakAraNAMta darEkE cAlI khAtIra mhUrta sOdatanAya jatanAya ghEtAta dEkhUna bhAgavata hAMNI sOdillyA mhurAtakO vhaDa mhatva AsAna hAlIMca jAllE lOkasabhA vEMcaNukEMta bhAjapAcO jO parAbhava jAlO tAcI mimAMsA jAvacI AnI tE khAtIra jApasAlarAna AshillyAMka tAMcI suvAta dAkhOvacI ashI mAgaNI jAtAlIta tyA yatnAMta lAlakrmal aDavANIna ADamELIM hADalIMta tAcEya phuDEM vacata tAMNI pakSAcyA pracArAcEM niyaMtraNa karatalyA arUNa jETalIM rAjyasabhEcO virOdhI pakSa phuDArI karUna prashastIca dilIcya parAbhavAcI mimAMsA ApalyAca AMgalaTa yEvapAka shakatA hEM vaLakhUna aDavANI Akramaka jAlyAta AnI pakSAna tAMcE mukhAra dimI ghAlyA ashEM citra disapAka lAgillEM tEM citra payasa karapAka pakSSAkSanAM rAjanAtaha siMgAna rAjastAbhyAMtanA ApalEM vEgaLEM rAjakAraNa cAlIka lAyalEM AnI aDavANIMcI shishyA vasuMdharA rAjEMcO rAjinAmO mAgalO vEMcaMmakAcyENa apAdanE vayalE bAshhAbhAca prasna ajUna suTAvO jAvaMka nA hO saMdEsha aDavANIM mErEna pAvOvapAcO tAMcO hO yatna AshillOya arthAta tO saMkEta pAvalO AnI EkE patrakAra parishEdacala nimitta karIta aDavANIna ciMtana basakEMta AmI vEMcaNukE vishIM nhaya tara mukhA vayalE vATE vishIM ulayatalE ashEM sAMgUna rAjanAthAcyAna rathAka jamanIra hADapAcI cAla khELLEya tikA pratishaha dilO mOhana bhAgavatAsa ciMtana basakEMta parAvbAkaLAcyA bhAsAbhAsa jAvapAka jAya mhUNa sAMgata tAMNI aDavANIMcO ajEMDA AnI paryAyAna khudda aDavANIca kAlabhAnA jAvapAka lAgalyAta mhaNapAcE saMkEta dilyAta \n"]}],"source":["x=\"भारतीय जनता पक्षाची तीन दिसांची चिंतन बसका शिमलाचे थंडसाणींत काल सोंपली. बसकेंतले चर्चे परस आदल्या संरक्षण मंत्र्याक धांवडावपाचे करणेचेच चड पडसाद उठले. बसकेचे दोन दीस पयलीं राष्ट्रीय स्वयंसेवक संघाचे सरसंघचालक मोहन भागवतान पक्षान तरणाट्या रगताक वाव दिवपाक जाय म्हूण सांगत लालकृष्ण अडवाणी आनी तांचे पिरोयेच्या फुडाऱयांक कावलांत वचपाची शिटकावणी दिल्ली. संघाच्या राजकारणांत दरेके चाली खातीर म्हूर्त सोदतनाय जतनाय घेतात. देखून भागवत हांणी सोदिल्ल्या म्हुर्ताक व्हड म्हत्व आसा. हालींच जाल्ले लोकसभा वेंचणुकेंत भाजपाचो जो पराभव जालो ताची मिमांसा जावची आनी ते खातीर जापसालदार आशिल्ल्यांक तांची सुवात दाखोवची अशी मागणी जाताली. त्या यत्नांत लालकृष्ण अडवाणीन आडमेळीं हाडलीं. ताचेय फुडें वचत तांणी पक्षाच्या प्रचाराचें नियंत्रण करतल्या अरूण जेटलीक राज्यसभेचो विरोधी पक्ष फुडारी करून प्रशस्तीच दिली. पराभवाची मिमांसा आपल्याच आंगलट येवपाक शकता हें वळखून अडवाणी आक्रमक जाल्यात आनी पक्षान तांचे मुखार दिमी घाल्या अशें चित्र दिसपाक लागिल्लें. तें चित्र पयस करपाक पक्षाध्यक्ष राजनाथ सिंगान राजस्थानांतल्यान आपलें वेगळें राजकारण चालीक लायलें आनी अडवाणींची शिश्या वसुंधरा राजेंचो राजिनामो मागलो. वेंचणुकेंतल्या अपेसा वयले भासाभासेचो प्रस्न अजून सुटावो जावंक ना हो संदेश अडवाणीं मेरेन पावोवपाचो तांचो हो यत्न आशिल्लो. अर्थात तो संकेत पावलो आनी एके पत्रकार परिशदेचें निमित्त करीत अडवाणीन चिंतन बसकेंत आमी वेंचणुके विशीं न्हय तर मुखा वयले वाटे विशीं उलयतले अशें सांगून राजनाथाच्या रथाक जमनीर हाडपाची चाल खेळ्ळे. तिका प्रतिशह दिलो मोहन भागवतान. चिंतन बसकेंत पराभवाचेरूय भासाभास जावपाक जाय म्हूण सांगत तांणी अडवाणींचो अॅजेंडा आनी पर्यायान खुद्द अडवाणीच कालबाह्म जावपाक लागल्यात म्हणपाचे संकेत दिल्यात\"\n","y=x.split()\n","\n","string1=''\n","for i in y:\n","    string1+=transliterate(i) + ' '\n","\n","print(string1)\n","    "]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"320px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":0}